{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"https://vbti.nl\"><img src=\"images/vbti_logo.png\" width=\"400\"></a>\n",
    "</div>\n",
    "\n",
    "# Reinforcement Learning\n",
    "This notebook supports the 'Reinforcement Learning' chapter of the [1-day masterclass \"Deep Learning\"](https://aiblog.nl/masterclass-deep-learning). It is not ment as a full course on deep learning, but rather gives you a flavor of the topic. For an in-depth AI training or consultancy please contact [VBTI](https://vbti.nl). \n",
    "\n",
    "Reinforcement Learning is an AI technique to learn an optimal sequence of actions. During the masterclass details of the action-value method, Q-learning, exploration/exploitation, discount factor and Deep Reinforcement Learning are explained. In this notebook you will build and train a RL agent that needs to optimize planning taxi trips.\n",
    "\n",
    "<div align=\"center\">\n",
    "<a href=\"https://aiblog.nl/masterclass-deep-learning\"><img src=\"images/rl.png\" width=\"400\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some default libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment preparation\n",
    "In this example the [gym tool](https://gym.openai.com) is used to create a simulation environment in which an agent needs to learn a task. The environment used is called 'Taxi-v3'. In this toy environment the agents needs to drive a taxi to pick up and drop passengers. \n",
    "\n",
    "> There are 4 locations (labeled by different letters) and your job is to pick up the passenger at one location and drop him off in another. You receive +20 points for a successful dropoff, and lose 1 point for every timestep it takes. There is also a 10 point penalty for illegal pick-up and drop-off actions. (['Taxi-v3'](https://gym.openai.com/envs/Taxi-v3/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions : Discrete(6)\n",
      "Number of states  : Discrete(500)\n",
      "Initial state     : 327\n"
     ]
    }
   ],
   "source": [
    "# import and create the simulation environment\n",
    "import gym\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "print(\"Number of actions : {}\".format(env.action_space))\n",
    "print(\"Number of states  : {}\".format(env.observation_space))\n",
    "\n",
    "initial_state = env.reset()\n",
    "print(\"Initial state     : {}\".format(initial_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# render environment\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Base classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Agent:    \n",
    "    \"\"\"Abstract Agent class.\"\"\"\n",
    "    def reset(self):\n",
    "        self.rewards = []\n",
    "        \n",
    "    def initialize_episode(self):\n",
    "        self.sum_rewards = 0\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        return None\n",
    "    \n",
    "    def update(self, state, action, next_state, reward):\n",
    "        self.sum_rewards = self.sum_rewards + reward\n",
    "    \n",
    "    def finalize_episode(self):\n",
    "        self.rewards.append(self.sum_rewards)\n",
    "        \n",
    "    def get_name(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    def plot_rewards(self, ylim=(-100,0)):\n",
    "        plt.figure(figsize=(18,5))\n",
    "        plt.plot(self.rewards)\n",
    "        plt.xlabel('episode')\n",
    "        plt.ylabel('sum of rewards')\n",
    "        plt.ylim(ylim)\n",
    "        plt.title(self.get_name())\n",
    "        \n",
    "\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def run_experiment(environment, agent, n_experiments=1, max_steps=100, render=False, sleep=0.01, n_epoch_update=1000, plot_stats=False):\n",
    "    # do some bookkeeping\n",
    "    stats_steps = []\n",
    "    stats_rewards = []\n",
    "    stats_penalties = []\n",
    "    stats_reward_per_step = []\n",
    "    \n",
    "    for n in range(n_experiments):\n",
    "        # reset environment and agent for this episode\n",
    "        state = environment.reset()\n",
    "        agent.initialize_episode()\n",
    "        \n",
    "        # render environment\n",
    "        if render:\n",
    "            environment.render()\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(sleep)\n",
    "        elif n % n_epoch_update ==0: # print progress\n",
    "            print(\"Run experiment : {} / {}\".format(n, n_experiments))\n",
    "        \n",
    "        # episode loop\n",
    "        steps = 0\n",
    "        penalties = 0\n",
    "        done = False\n",
    "        while (not done) and (steps < max_steps):\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done, info = environment.step(action)\n",
    "            agent.update(state, action, next_state, reward)\n",
    "            state = next_state\n",
    "            steps = steps + 1\n",
    "            \n",
    "            if render:\n",
    "                environment.render()\n",
    "                clear_output(wait=True)\n",
    "                time.sleep(sleep)\n",
    "             \n",
    "            # count penalties\n",
    "            if reward==-10:\n",
    "                penalties += 1\n",
    "            \n",
    "        agent.finalize_episode()\n",
    "        stats_penalties.append(penalties)\n",
    "        stats_steps.append(steps)\n",
    "        stats_rewards.append(agent.sum_rewards)\n",
    "        stats_reward_per_step.append(agent.sum_rewards / steps)\n",
    "    \n",
    "    if render:\n",
    "        environment.render()\n",
    "        print('')\n",
    "    else:\n",
    "        print('Done.\\n')\n",
    "\n",
    "    print(\"Average reward       : {}\".format(np.mean(stats_rewards)))\n",
    "    print(\"Average #penalties   : {}\".format(np.mean(stats_penalties)))\n",
    "    print(\"Average #steps       : {}\".format(np.mean(stats_steps)))\n",
    "    print(\"Average #reward/step : {}\".format(np.mean(stats_reward_per_step)))\n",
    "    \n",
    "    if plot_stats:\n",
    "        plt.plot(stats_steps, label='#steps')\n",
    "        plt.plot(stats_penalties, label='#penalties')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Q-learning Agent\n",
    "In the masterclass the Q-learning technique is explained. Following this methods, an agent learns to evaluate a state-action combination by using the following rule:\n",
    "\n",
    "$$\n",
    "Q(s_t,a_t) \\leftarrow Q(s_t,a_t) + \\alpha \\left[ R_{t+1} +\\gamma \\max\\limits_{a} Q(s_{t+1},a) - Q(s_t,a_t) \\right]\n",
    "$$\n",
    "\n",
    "The code below implements this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent(Agent):\n",
    "    def __init__(self, n_states, n_actions, epsilon=0.1, gamma=0.9, alpha=0.1):\n",
    "        Agent.__init__(self)\n",
    "        \n",
    "        self.n_states = n_states\n",
    "        self.n_actions = n_actions\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.learn = True\n",
    "                \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        Agent.reset(self)                \n",
    "        self.Q = np.zeros((self.n_states, self.n_actions))\n",
    "                \n",
    "    def get_action(self, state):\n",
    "        # e-greedy\n",
    "        if self.learn & (np.random.random()<self.epsilon): # explore\n",
    "            a = np.random.randint(self.n_actions)\n",
    "        else: # exploit\n",
    "            a = np.argmax(self.Q[state,:])\n",
    "        return a\n",
    "    \n",
    "    def update(self, state, action, next_state, reward):\n",
    "        if self.learn:\n",
    "            self.Q[state, action] = self.Q[state, action] + self.alpha * (reward + \n",
    "                                                                          self.gamma * np.max(self.Q[next_state,:]) -\n",
    "                                                                          self.Q[state, action])\n",
    "        Agent.update(self, state, action, next_state, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Q-learning agent\n",
    "agent_Q = QLearningAgent(n_states=500, n_actions=6, epsilon=0.1, alpha=0.1, gamma=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train agent\n",
    "To train a Q-learning agent it needs to try to drive the taxi many times. A maximum duration of 200 steps will be allowed to pick up and drop a passenger. \n",
    "\n",
    "First, let's see how well the agents performance without learning. The average performance over 10 experimens is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "\n",
      "Average reward       : -200.0\n",
      "Average #penalties   : 0.0\n",
      "Average #steps       : 200.0\n",
      "Average #reward/step : -1.0\n"
     ]
    }
   ],
   "source": [
    "# calculate performance of agent\n",
    "# Note: sometimes the agent does not move but the simulation does run. Be patient! ;)\n",
    "agent_Q.learn = False\n",
    "run_experiment(env, agent_Q, n_experiments=10, max_steps=200, render=True)\n",
    "agent_Q.learn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely, the agent will performance very bad (average reward: -200, average number of steps: 200). Therefore 20.000 experiments are carried out during which the agent learns to carry out its job at best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run experiment : 0 / 20000\n",
      "Run experiment : 10000 / 20000\n",
      "Done.\n",
      "\n",
      "Average reward       : -2.03835\n",
      "Average #penalties   : 0.6131\n",
      "Average #steps       : 17.3745\n",
      "Average #reward/step : 0.27727722386973236\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment(env, agent_Q, n_experiments=20_000, max_steps=200, render=False, n_epoch_update=10_000, plot_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average reward should have increased and the average number of steps should have decreased. We can now measure the performance of the agent after learning by averaging the performance over 10 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "Average reward       : 8.0\n",
      "Average #penalties   : 0.0\n",
      "Average #steps       : 13.0\n",
      "Average #reward/step : 0.627062937062937\n"
     ]
    }
   ],
   "source": [
    "# calculate performance of agent\n",
    "agent_Q.learn = False\n",
    "run_experiment(env, agent_Q, n_experiments=10, max_steps=200, render=True, sleep=0.1)\n",
    "agent_Q.learn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to go further from here?\n",
    "This notebook provides a basic processing pipeline for building a reinforcement learning agent that learns to carry out a job. Experiment a little bit yourself by changing the exploration parameter epsilon and discount factor gamma. Try to increase the reward or shorten the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
